{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhHv/+PGCjcTjiX95gevT2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanChen12035/capstone/blob/main/two_tower_BERTmodel_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE0qQNQ-GZAc",
        "outputId": "55660aef-b194-427b-ad54-d37f7fc81c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.8.0 --quiet\n",
        "!pip install transformers==4.15.0 --quiet\n",
        "!pip install scikit-learn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0SE9cNaGaVN",
        "outputId": "2e1fd6f5-97d0-419e-85ca-727c4a040eda"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DlQmjvDGabe",
        "outputId": "dda2f17c-1836-4ff7-8a32-4a5bd49a1fcb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-7f5c17d8-3c82-f9c3-4de6-9a053e98618a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda, Dropout, Conv1D, GlobalMaxPooling1D, Concatenate, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from transformers import logging\n",
        "logging.set_verbosity_error()\n",
        "import sklearn as sk\n",
        "import os\n",
        "from nltk.data import find\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "xGYigkBbGaeM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./job_PII_diagnosis_2.csv\", error_bad_lines=False)\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "6N6ezkUJGagi",
        "outputId": "c9bac98b-205b-421a-a117-111f3927cbf4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-66fd34e864f1>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv(\"./job_PII_diagnosis_2.csv\", error_bad_lines=False)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              prompt  related_to_job\n",
              "0  I am doing Marketing Intern at US, NY, New Yor...               1\n",
              "1  I am doing in the industry of Success What we ...               1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b5e3352-4336-42f2-9f62-d2025670a1c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>related_to_job</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am doing Marketing Intern at US, NY, New Yor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am doing in the industry of Success What we ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b5e3352-4336-42f2-9f62-d2025670a1c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b5e3352-4336-42f2-9f62-d2025670a1c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b5e3352-4336-42f2-9f62-d2025670a1c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e7ac44da-eaac-46e1-8e48-5651e4f6ce2a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7ac44da-eaac-46e1-8e48-5651e4f6ce2a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e7ac44da-eaac-46e1-8e48-5651e4f6ce2a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1907,\n        \"samples\": [\n          \"My skin has been acting up lately, it's been really itchy and I've been getting rashes. Some patches of my skin are a different color than the rest of my skin, and I have some lumps or bumps on my skin that weren't there before.\",\n          \"My company is at US, OR, Portland and they payroll is around negotiable Novitex Enterprise Solutions, formerly Pitney Bowes Management Services, delivers innovative document and communications management solutions that hel, The Customer Service Associate will be based in Portland, OR. The right candidate will be an integral part of our talented team, supporting our contin\",\n          \"As an essay writer, I am committed to crafting compelling narratives while adhering to the specific instructions provided. In this instance, I have been entrusted with the responsibility of incorporating the following personal information into an essay:\\n\\nNAME_STUDENT: Lindsey Lydia Santos Hodge\\nUSERNAME: wilkersonmatthew, gordongary\\nID_NUM: 2499 XO, 2UE22\\nPHONE_NUM: (201)934-9902x171\\nURL_PERSONAL: https://youtube.com/c/garrett54\\nSTREET_ADDRESS: 691 Alan Brook\\\\nZavalatown, MS 41213\\n\\nRest assured that each of these details will be seamlessly woven into the fabric of my essay.\\n\\nEducation has always been a beacon of hope in my life, illuminating the path to personal growth and a fulfilling career. From a tender age, I have been an avid learner, eager to soak up knowledge like a sponge. This thirst for education led me to pursue a degree in [insert major] at [insert university name], where I excelled academically and forged lifelong connections.\\n\\nThroughout my academic journey, I have had the privilege of interacting with renowned professors such as Dr. Emily Carter and Dr. Robert Garcia. Their guidance and mentorship have been instrumental in shaping my intellectual curiosity and critical thinking skills. Notably, my research under Dr. Garcia's supervision on [insert research topic] earned recognition at the [insert conference name], showcasing my dedication to scientific inquiry.\\n\\nBeyond the classroom, I am an active member of the [insert club or organization name] at my university. Through this organization, I have had the opportunity to connect with like-minded individuals, engage in community service, and develop my leadership abilities. I am particularly proud of our recent initiative to [insert description of initiative], which had a tangible impact on our local community.\\n\\nAs a well-rounded individual, I am also passionate about [insert hobby or interest]. I have been practicing [insert hobby or interest] for [insert number] years, and it has become an integral part of my life. Through [insert hobby or interest], I have learned the importance of perseverance, patience, and attention to detail.\\n\\nIn the tapestry of my life, my family and friends are vibrant threads that add color and meaning to every day. I am eternally grateful for their unwavering support and encouragement, which have been the bedrock of my successes.\\n\\nAs I embark on the next chapter of my life, armed with my education, experiences, and unwavering support system, I am confident that I am well-equipped to make a meaningful contribution to society. I am eager to apply my knowledge and skills to address the challenges facing our world and to create positive change for future generations.\\n\\nIn closing, I would like to express my gratitude for the opportunity to share my personal information with you and to showcase the multifaceted nature of my identity. I am confident that my unique experiences and perspectives will enable me to make a valuable contribution to your organization.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"related_to_job\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['prompt'], df['related_to_job'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Z3oOgZPRGaiq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#allow us to get the hidden layer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "id": "I04VEB2SGf2Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list = X_train.apply(lambda x: x.replace('\\xa0', ' ')).tolist()\n",
        "X_val_list = X_test.apply(lambda x: x.replace('\\xa0', ' ')).tolist()\n",
        "\n",
        "# train\n",
        "bert_train_tokenized = bert_tokenizer(X_train_list,\n",
        "    max_length=128,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='tf')\n",
        "bert_train_inputs = [bert_train_tokenized.input_ids,\n",
        "    bert_train_tokenized.token_type_ids,\n",
        "    bert_train_tokenized.attention_mask]\n",
        "bert_train_labels = np.array(y_train)\n",
        "\n",
        "# valdation\n",
        "bert_val_tokenized = bert_tokenizer(X_val_list,\n",
        "    max_length=128,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='tf')\n",
        "bert_val_inputs = [bert_val_tokenized.input_ids,\n",
        "    bert_val_tokenized.token_type_ids,\n",
        "    bert_val_tokenized.attention_mask]\n",
        "bert_val_labels = np.array(y_test)"
      ],
      "metadata": {
        "id": "mNf2HahtGjuB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_list[0])\n",
        "print(bert_train_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpMIPFkpGkk7",
        "outputId": "ff0b6ddc-64db-4329-aa08-a60fe06b3a53"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " nan, Overview: Looking for an experienced hands-on Java developer with at least 7-10 years’ experience to join the team. We are building Stress testing sol, and the benefits: negotiable\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = X_train_list[0]\n",
        "encoded_input = bert_tokenizer.encode_plus(text, return_tensors='pt')\n",
        "encoded_input['input_ids'].size(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAfRlnotTRU-",
        "outputId": "a86cf9ed-46ab-4d6f-b2f7-199f56a5b9c1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12 layers of transformer\n",
        "#A drop out layer + dense layer with 100 hidden layer size on top + final layer with sigmoid as activation function\n",
        "def create_bert_cls_model(bert_base_model,\n",
        "                          max_sequence_length=128,\n",
        "                          hidden_size = 100,\n",
        "                          dropout=0.3,\n",
        "                          learning_rate=0.0001): #0.0005\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT. Use the CLS Token output for classification purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    bert_base_model.trainable = True #True\n",
        "\n",
        "    #input layers of BERT, shape (batch, max_sequence_length), model will be fit with bert_train_tokenized\n",
        "    input_ids = Input(shape=(max_sequence_length,), dtype=tf.int32, name='input_ids')\n",
        "    token_type_ids = Input(shape=(max_sequence_length,), dtype=tf.int32, name='token_type_ids')\n",
        "    attention_mask = Input(shape=(max_sequence_length,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "    inputs = [input_ids, token_type_ids, attention_mask]\n",
        "\n",
        "    #BERT output, last_hidden_state shape (batch, max_sequence_length, embedding dimensions)\n",
        "    bert_output = bert_base_model(input_ids=input_ids,\n",
        "                                  token_type_ids=token_type_ids,\n",
        "                                  attention_mask=attention_mask)\n",
        "\n",
        "    #Extract the CLS token's output, the embedding representation of first token of every sentence, shape(batch, embedding dimensions)\n",
        "    cls_token_output = bert_output[0][:, 0, :] # CLS token output from the last layer\n",
        "\n",
        "    #Add a dropout layer\n",
        "    x = Dropout(dropout)(cls_token_output)\n",
        "\n",
        "    #Add a fully connected layer for classification\n",
        "    x = Dense(hidden_size, activation='relu')(x)\n",
        "\n",
        "    #Final output layer for classification, assuming it's binary task\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    #Model complie\n",
        "    classification_model = Model(inputs=inputs, outputs=output)\n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                                 loss='binary_crossentropy',\n",
        "                                 metrics=['accuracy'])\n",
        "    return classification_model"
      ],
      "metadata": {
        "id": "8ORhE1CTOI8A"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_cls_model_classification = create_bert_cls_model(bert_model)"
      ],
      "metadata": {
        "id": "b4aDvzCrOOIZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_cls_bert= bert_cls_model_classification.fit(bert_train_inputs,\n",
        "                                                    bert_train_labels,\n",
        "                                                    epochs=1, #2\n",
        "                                                    batch_size=16, #8\n",
        "                                                    validation_data=(bert_val_inputs, bert_val_labels))\n",
        "\n",
        "# 56/567 accuracy 0.95 data examples 4000 batch 8 lr 0.00005\n",
        "# 12/100 accuracy 0.92 data examples 2000 batch 16 lr 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2AR-EkkPWq9",
        "outputId": "7a9ec804-f2ba-466c-d90a-d47201b87438"
      },
      "execution_count": 25,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 1520s 15s/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.1692 - val_accuracy: 0.9800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_cls_model_classification.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZloN6moAyuM",
        "outputId": "8a24c57c-2218-4964-b9e1-97a27a0818a9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]',         \n",
            "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
            "                                n_state=(None, 128,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model_1[0][0]']        \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dropout_75 (Dropout)           (None, 768)          0           ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 100)          76900       ['dropout_75[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            101         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,387,273\n",
            "Trainable params: 108,387,273\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_cls_model_classification.save('./two_tower_bert.h5')"
      ],
      "metadata": {
        "id": "DDG22mLDJIJs"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "custom_objects = {'TFBertModel': TFBertModel}\n",
        "model = load_model('./two_tower_bert.h5', custom_objects=custom_objects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRTc6uqVJNe8",
        "outputId": "0e6aae48-17f7-4291-ff51-63380bcb9bcc"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT as the embedding for the vector database"
      ],
      "metadata": {
        "id": "FOhbOzX7CWdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embedding(text, model):\n",
        "  bert_embedding_model = Model(inputs=[model.input],\n",
        "                               outputs=model.get_layer('tf.__operators__.getitem_1').output)\n",
        "  bert_train_tokenized = bert_tokenizer(text,\n",
        "                                        max_length=128,\n",
        "                                        truncation=True,\n",
        "                                        padding='max_length',\n",
        "                                        return_tensors='tf')\n",
        "  bert_train_inputs = [bert_train_tokenized.input_ids,\n",
        "                       bert_train_tokenized.token_type_ids,\n",
        "                       bert_train_tokenized.attention_mask]\n",
        "  return bert_embedding_model.predict(bert_train_inputs)\n",
        "\n",
        "text = X_train_list[2]\n",
        "embeddings = generate_embedding(text, model)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ESnLUrVX5E",
        "outputId": "a2462251-ccd5-4573-c9b5-5ce4818af128"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu transformers torch --quiet"
      ],
      "metadata": {
        "id": "Z8lkF_AG1Qad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "dimension = 768  # Dimension of BERT-base embeddings\n",
        "nlist = 50  # Number of clusters for quantization, adjust based on your dataset size\n",
        "\n",
        "# Using an IndexFlatL2 for simplicity, which is a basic but exact method for similarity search\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# For larger datasets, consider using an IVF index to speed up search at the cost of slight accuracy loss\n",
        "# quantizer = faiss.IndexFlatL2(dimension)\n",
        "# index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)\n",
        "# index.train(embeddings) # You need to train the index with some embeddings if using IVF"
      ],
      "metadata": {
        "id": "OxNZxBC-2D5h"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_vectordatabase(embedding):\n",
        "  embeddings = np.array(embedding, dtype=\"float32\")\n",
        "  embeddings = embeddings.reshape(-1, embeddings.shape[-1])\n",
        "  return embeddings\n",
        "\n",
        "\n",
        "# Add embeddings to the index\n",
        "index.add(embedding_vectordatabase(embeddings))"
      ],
      "metadata": {
        "id": "QSZwS68o2GRZ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Business Analyst - CRM and the salary range is negotiable Our passion for improving quality of life through geography is at the heart of everything we do.\n",
        "Esri’s geographic information system (GIS) technolog\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0jHMeMPkEjyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"My name is Ryan and I have a headache\"\n",
        "query_embedding = generate_embedding(query_text)\n",
        "query_embedding = embedding_vectordatabase(query_embedding)\n",
        "\n",
        "# Search the index\n",
        "k = 5\n",
        "distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "print(\"Indices of closest embeddings:\", indices)\n",
        "print(\"Distances:\", distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWmGzszY2JN2",
        "outputId": "a752349e-e44c-4f41-c9ff-a83764e96945"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "Indices of closest embeddings: [[ 1  2  0 -1 -1]]\n",
            "Distances: [[9.7718237e+02 9.7718237e+02 9.7718237e+02 3.4028235e+38 3.4028235e+38]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_vectors = index.ntotal\n",
        "print(f\"The index contains {num_vectors} vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzm2yVuoGS_C",
        "outputId": "a4b024e8-9332-48cb-eef8-d27a2ff51235"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The index contains 3 vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "model.save('path_to_my_model.h5')"
      ],
      "metadata": {
        "id": "goAvYJ2ZFqrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('./two_tower_bert.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "wfhZkHsgIYnJ",
        "outputId": "c6eb48fd-aa0f-4275-a730-2163be37ced6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_08bcbb63-3d2c-4289-b9cc-c8cd5a508743\", \"two_tower_bert.h5\", 1296787128)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}