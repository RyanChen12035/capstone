{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFM+GQ3vxohc+lfVqjeMGX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyanChen12035/capstone/blob/main/similar_search_models_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fb9L26OH0pku"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.8.0 --quiet\n",
        "!pip install transformers==4.15.0 --quiet\n",
        "!pip install scikit-learn --quiet\n",
        "!pip install faiss-gpu transformers torch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda, Dropout, Conv1D, GlobalMaxPooling1D, Concatenate, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from transformers import logging\n",
        "logging.set_verbosity_error()\n",
        "import sklearn as sk\n",
        "import os\n",
        "from nltk.data import find\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ],
      "metadata": {
        "id": "8_sEQL4O0qim"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY6Q5kml0umj",
        "outputId": "ebf4255b-e568-439a-d010-62dc18b10b2f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# model_v3\n",
        "# model_v4\n",
        "# model_freeze_classifer\n",
        "\n",
        "custom_objects = {'TFBertModel': TFBertModel}\n",
        "model_v3data = load_model('./drive/MyDrive/Two_tower_level4_PII/two_tower_bert_v3.h5', custom_objects=custom_objects)\n",
        "model_v4data = load_model('./drive/MyDrive/Two_tower_level4_PII/two_tower_bert_v4.h5', custom_objects=custom_objects)\n",
        "model_v5data = load_model('./drive/MyDrive/Two_tower_level4_PII/two_tower_bert_v5.h5', custom_objects=custom_objects)\n",
        "model_freeze_classifer_v3v5 = load_model('./drive/MyDrive/Two_tower_level4_PII/two_tower_bert_freezeclassifer_v3v5.h5', custom_objects=custom_objects)\n",
        "model_freeze_classifer_v3v4 = load_model('./drive/MyDrive/Two_tower_level4_PII/two_tower_bert_freezeclassifer_v3v4.h5', custom_objects=custom_objects)\n",
        "model_freeze_classifer_v4v5 = load_model('./drive/MyDrive/Two_tower_level4_PII/two_tower_bert_freezeclassifer_v4v5.h5', custom_objects=custom_objects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsEq_Gu50xBY",
        "outputId": "dbf7f5f6-986c-4d7c-b669-1916ff613fb3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1mcph2y9Sxc",
        "outputId": "7f8786bf-70dd-4265-b967-57103d42964b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_v5data.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP0vYvBw-mAc",
        "outputId": "c664dc05-4bdb-4caf-bada-228830ff356c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_2 (TFBertModel)  TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]',         \n",
            "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
            "                                n_state=(None, 128,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model_2[0][0]']        \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 768)          0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 100)          76900       ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            101         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,387,273\n",
            "Trainable params: 108,387,273\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cls extraction\n",
        "def generate_embedding_cls(text, model):\n",
        "  bert_embedding_model = Model(inputs=[model.input],\n",
        "                               outputs=model.get_layer('tf.__operators__.getitem').output)\n",
        "  bert_train_tokenized = bert_tokenizer(text,\n",
        "                                        max_length=128,\n",
        "                                        truncation=True,\n",
        "                                        padding='max_length',\n",
        "                                        return_tensors='tf')\n",
        "  bert_train_inputs = [bert_train_tokenized.input_ids,\n",
        "                       bert_train_tokenized.token_type_ids,\n",
        "                       bert_train_tokenized.attention_mask]\n",
        "  return bert_embedding_model.predict(bert_train_inputs)\n"
      ],
      "metadata": {
        "id": "_zxly7DO1xor"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# maximum pooling\n",
        "\n",
        "def generate_embedding_max(text, model, bert_name):\n",
        "    # same input\n",
        "    input_ids = model.get_layer('input_ids').input\n",
        "    attention_mask = model.get_layer('attention_mask').input\n",
        "    token_type_ids = model.get_layer('token_type_ids').input\n",
        "    #get bert output\n",
        "    bert_layer = model.get_layer(bert_name)\n",
        "    bert_output = bert_layer([input_ids, attention_mask, token_type_ids])\n",
        "    # Apply max pooling on the sequence output (last_hidden_state: (batch, sequence, embedding dimensions))\n",
        "    pooled_output = GlobalMaxPooling1D()(bert_output[0])\n",
        "    # Create a new model for embedding extraction\n",
        "    embedding_model = Model(inputs=[input_ids, attention_mask, token_type_ids],\n",
        "                            outputs=pooled_output)\n",
        "\n",
        "    bert_train_tokenized = bert_tokenizer(text,\n",
        "                                        max_length=128,\n",
        "                                        truncation=True,\n",
        "                                        padding='max_length',\n",
        "                                        return_tensors='tf')\n",
        "    bert_train_inputs = [bert_train_tokenized.input_ids,\n",
        "                       bert_train_tokenized.token_type_ids,\n",
        "                       bert_train_tokenized.attention_mask]\n",
        "\n",
        "    return embedding_model.predict(bert_train_inputs)"
      ],
      "metadata": {
        "id": "Uz6AmIFi2VXj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the size of embeddings\n",
        "text = \"\"\"As Jose, a student at Johnnyfurt Higher Institute, I have learned the importance of time management and organization through my academic journey. With my student ID number DNM7052, I have had the opportunity to engage in various lI am doing H1B SPONSOR FOR L1/L2/OPT at US, NY, New York  \"\"\"\n",
        "embeddings_v3 = generate_embedding_cls(text, model_v3data)\n",
        "embeddings_v4 = generate_embedding_cls(text, model_v4data)\n",
        "embeddings_v5 = generate_embedding_cls(text, model_v5data)\n",
        "\n",
        "embeddings_freeze_classifer_v3v4 = generate_embedding_cls(text, model_freeze_classifer_v3v4)\n",
        "embeddings_freeze_classifer_v4v5 = generate_embedding_cls(text, model_freeze_classifer_v4v5)\n",
        "embeddings_freeze_classifer_v3v5 = generate_embedding_cls(text, model_freeze_classifer_v3v5)\n",
        "\n",
        "embeddings_v5_max = generate_embedding_max(text, model_v5data, bert_name='tf_bert_model_2')\n",
        "embeddings_freeze_classifer_v4v5_max = generate_embedding_max(text, model_freeze_classifer_v4v5, bert_name='tf_bert_model_5')\n",
        "\n",
        "print(embeddings_v3.shape, embeddings_v4.shape, embeddings_v5.shape, embeddings_freeze_classifer_v3v4.shape, embeddings_freeze_classifer_v4v5.shape, embeddings_freeze_classifer_v3v5.shape, embeddings_v5_max.shape, embeddings_freeze_classifer_v4v5_max.shape)"
      ],
      "metadata": {
        "id": "AZ1V2Nic9ZA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (768,1) to 768\n",
        "def embedding_vectordatabase(embedding):\n",
        "  embeddings = np.array(embedding, dtype=\"float32\")\n",
        "  embeddings = embeddings.reshape(-1, embeddings.shape[-1])\n",
        "  return embeddings"
      ],
      "metadata": {
        "id": "3eetTYD034-c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create vector databases\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "dimension = 768  # Dimension of BERT-base embeddings\n",
        "\n",
        "index_cls_v3 = faiss.IndexFlatL2(dimension)\n",
        "index_cls_v4 = faiss.IndexFlatL2(dimension)\n",
        "index_cls_v5 = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "index_cls_freeze_classifier_v3v4 = faiss.IndexFlatL2(dimension)\n",
        "index_cls_freeze_classifier_v3v5 = faiss.IndexFlatL2(dimension)\n",
        "index_cls_freeze_classifier_v4v5 = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "index_v5_max = faiss.IndexFlatL2(dimension)\n",
        "index_freeze_classifer_v4v5_max = faiss.IndexFlatL2(dimension)"
      ],
      "metadata": {
        "id": "p2JPAnA21CWB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding: model_v3 + cls\n",
        "# embedding: model_v4 + cls\n",
        "# embedding: model_freeze_classifer + cls\n",
        "# embedding: model_freeze_classifer + max pooling\n",
        "\n",
        "\n",
        "level_four_job = [\"Competitive salary for iPhone project management roles\",\n",
        "                  \"Relocation benefits for Apple Cupertino campus positions\",\n",
        "                  \"Exclusive health and wellness benefits for iPhone development team members\",\n",
        "                  \"Stock options and bonuses for iPhone project milestones\",\n",
        "                  \"Collaborative workspaces at Apple's Silicon Valley locations\",\n",
        "                  \"Professional development programs for iOS project leads\",\n",
        "                  \"Confidentiality agreements for upcoming iPhone projects\",\n",
        "                  \"Global travel opportunities for iPhone supplier audits\",\n",
        "                  \"Flexible working hours for Apple's product development teams\",\n",
        "                  \"Team-building retreats for iPhone project managers\"]\n",
        "\n",
        "for input in level_four_job:\n",
        "  embeddings = generate_embedding_cls(input, model_v3data)\n",
        "  index_cls_v3.add(embedding_vectordatabase(embeddings))\n",
        "\n",
        "  embeddings = generate_embedding_cls(input, model_v4data)\n",
        "  index_cls_v4.add(embedding_vectordatabase(embeddings))\n",
        "\n",
        "  embeddings = generate_embedding_cls(input, model_v5data)\n",
        "  index_cls_v5.add(embedding_vectordatabase(embeddings))\n",
        "\n",
        "  embeddings = generate_embedding_cls(input, model_freeze_classifer_v3v4)\n",
        "  index_cls_freeze_classifier_v3v4.add(embedding_vectordatabase(embeddings))\n",
        "\n",
        "  embeddings = generate_embedding_cls(input, model_freeze_classifer_v3v5)\n",
        "  index_cls_freeze_classifier_v3v5.add(embedding_vectordatabase(embeddings))\n",
        "\n",
        "  embeddings = generate_embedding_cls(input, model_freeze_classifer_v4v5)\n",
        "  index_cls_freeze_classifier_v4v5.add(embedding_vectordatabase(embeddings))\n",
        "\n",
        "  embeddings = generate_embedding_max(text, model_v5data, bert_name='tf_bert_model_2')\n",
        "  index_v5_max.add(embedding_vectordatabase(embeddings))\n",
        "\n",
        "  embeddings = generate_embedding_max(text, model_freeze_classifer_v4v5, bert_name='tf_bert_model_5')\n",
        "  index_freeze_classifer_v4v5_max.add(embedding_vectordatabase(embeddings))\n",
        "\n",
        "print(index_cls_v3.ntotal, index_cls_v4.ntotal, index_cls_v5.ntotal, index_cls_freeze_classifier_v3v4.ntotal, index_cls_freeze_classifier_v3v5.ntotal, index_cls_freeze_classifier_v4v5.ntotal, index_v5_max.ntotal, index_freeze_classifer_v4v5_max.ntotal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoPFJuHI4CfF",
        "outputId": "31c0690d-2562-4302-c8e0-d3a17d52b963"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 10 10 10 10 10 10 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare distance for a input and four vector database.\n",
        "# based on \"Relocation benefits for Apple Cupertino campus positions\", ask GPT to generate a prompt (#1)\n",
        "text = \"\"\"As Taylor Morgan, I am preparing to discuss my health concerns and lifestyle changes due to my recent relocation for a position at Apple's Cupertino campus.\n",
        "\"\"\"\n",
        "# Indices of closest embeddings for v3 model: [[1 6 7]]\n",
        "# Distances for v3 model: [[462.62048 557.87604 562.0688 ]]\n",
        "# Indices of closest embeddings for v4 model: [[8 7 3]]\n",
        "# Distances for v4 model: [[834.939   842.25964 842.5376 ]]\n",
        "# Indices of closest embeddings for v5 model: [[1 6 4]]\n",
        "# Distances for v5 model: [[149.1654  152.35236 153.35999]]\n",
        "# Indices of closest embeddings for fc_v3v4 model: [[0 3 8]]\n",
        "# Distances for fc_v3v4 model: [[664.42206 664.51105 665.29034]]\n",
        "# Indices of closest embeddings for fc_v4v5 model: [[4 6 2]]\n",
        "# Distances for fc_v4v5 model: [[521.54614 548.7949  550.61694]]\n",
        "# Indices of closest embeddings for fc_v3v5 model: [[4 6 1]]\n",
        "# Distances for fc_v3v5 model: [[387.16553 421.3154  462.21545]]\n",
        "# Indices of closest embeddings for fcm_v5 model: [[1 2 0]]\n",
        "# Distances for fcm_v5 model: [[94.93431 94.93431 94.93431]]\n",
        "# Indices of closest embeddings for fcm_v4v5 model: [[1 2 0]]\n",
        "# Distances for fcm_v4v5 model: [[99.05984 99.05984 99.05984]]\n",
        "\n",
        "#based on \"Global travel opportunities for iPhone supplier audits\" (#7)\n",
        "text = \"\"\"\n",
        "As Alex Rivera, I am reporting on the health implications and challenges faced due to my role involving global travel for iPhone supplier audits.\n",
        "\"\"\"\n",
        "# Indices of closest embeddings for v3 model: [[1 7 6]]\n",
        "# Distances for v3 model: [[175.7427  207.36827 233.06667]]\n",
        "# Indices of closest embeddings for v4 model: [[7 8 2]]\n",
        "# Distances for v4 model: [[621.7367  626.84393 627.2821 ]]\n",
        "# Indices of closest embeddings for v5 model: [[6 7 2]]\n",
        "# Distances for v5 model: [[45.748867 49.99069  51.427288]]\n",
        "# Indices of closest embeddings for fc_v3v4 model: [[4 2 8]]\n",
        "# Distances for fc_v3v4 model: [[1.6468006 1.7377512 1.7633522]]\n",
        "# Indices of closest embeddings for fc_v4v5 model: [[4 2 6]]\n",
        "# Distances for fc_v4v5 model: [[59.87197 69.83478 71.50404]]\n",
        "# Indices of closest embeddings for fc_v3v5 model: [[4 6 1]]\n",
        "# Distances for fc_v3v5 model: [[ 67.106606 105.07139  140.9225  ]]\n",
        "# Indices of closest embeddings for fcm_v5 model: [[1 2 0]]\n",
        "# Distances for fcm_v5 model: [[0. 0. 0.]]\n",
        "# Indices of closest embeddings for fcm_v4v5 model: [[1 2 0]]\n",
        "# Distances for fcm_v4v5 model: [[0. 0. 0.]]\n",
        "\n",
        "# 8. longer? \"Flexible working hours for Apple's product development teams\"\n",
        "text = \"\"\"\n",
        "As Jordan Kim, I'm addressing the impact of flexible working hours on my health as part of Apple's product development team. Since the implementation of flexible working hours, I've noticed significant changes in my daily routine, some beneficial and others challenging. The ability to adjust my work hours has afforded me a greater work-life balance, allowing for more time spent with family and engaging in personal hobbies. However, without the structure of fixed working hours, I've found it difficult to establish a consistent sleep schedule, leading to occasional insomnia and varying energy levels throughout the day.\n",
        "\"\"\"\n",
        "# Indices of closest embeddings for v3 model: [[1 6 7]]\n",
        "# Distances for v3 model: [[442.27026 531.46814 534.8041 ]]\n",
        "# Indices of closest embeddings for v4 model: [[8 6 3]]\n",
        "# Distances for v4 model: [[849.8129  857.4177  858.35767]]\n",
        "# Indices of closest embeddings for v5 model: [[2 6 9]]\n",
        "# Distances for v5 model: [[ 98.07463  99.06271 100.05426]]\n",
        "# Indices of closest embeddings for fc_v3v4 model: [[1 7 8]]\n",
        "# Distances for fc_v3v4 model: [[156.9984  157.8388  158.15071]]\n",
        "# Indices of closest embeddings for fc_v4v5 model: [[4 2 6]]\n",
        "# Distances for fc_v4v5 model: [[566.60895 589.8434  590.8391 ]]\n",
        "# Indices of closest embeddings for fc_v3v5 model: [[4 6 1]]\n",
        "# Distances for fc_v3v5 model: [[215.80788 261.38766 304.94348]]\n",
        "# Indices of closest embeddings for fcm_v5 model: [[1 2 0]]\n",
        "# Distances for fcm_v5 model: [[214.11975 214.11975 214.11975]]\n",
        "# Indices of closest embeddings for fcm_v4v5 model: [[1 2 0]]\n",
        "# Distances for fcm_v4v5 model: [[180.59593 180.59593 180.59593]]\n",
        "\n",
        "# 8. sentence level\n",
        "text = \"\"\"\n",
        "As Jordan Kim, I'm addressing the impact of flexible working hours on my health as part of Apple's product development team.\n",
        "\"\"\"\n",
        "# Indices of closest embeddings for v3 model: [[7 4 1]]\n",
        "# Distances for v3 model: [[141.25726 142.04306 148.1364 ]]\n",
        "# Indices of closest embeddings for v4 model: [[5 9 8]]\n",
        "# Distances for v4 model: [[434.44342 434.8328  437.09268]]\n",
        "# Indices of closest embeddings for v5 model: [[8 6 4]]\n",
        "# Distances for v5 model: [[27.352757 27.495752 29.006763]]\n",
        "# Indices of closest embeddings for fc_v3v4 model: [[4 8 2]]\n",
        "# Distances for fc_v3v4 model: [[2.7517064 2.8037987 2.904843 ]]\n",
        "# Indices of closest embeddings for fc_v4v5 model: [[4 2 6]]\n",
        "# Distances for fc_v4v5 model: [[79.770325 93.841736 99.04136 ]]\n",
        "# Indices of closest embeddings for fc_v3v5 model: [[4 6 1]]\n",
        "# Distances for fc_v3v5 model: [[ 63.460854 107.30418  140.4897  ]]\n",
        "# Indices of closest embeddings for fcm_v5 model: [[1 2 0]]\n",
        "# Distances for fcm_v5 model: [[32.360844 32.360844 32.360844]]\n",
        "# Indices of closest embeddings for fcm_v4v5 model: [[1 2 0]]\n",
        "# Distances for fcm_v4v5 model: [[25.956692 25.956692 25.956692]]\n",
        "\n",
        "\n",
        "# diagnosis, no job related information\n",
        "text = \"I've been having a lot of pain in my neck and back. I've also been having trouble with my balance and coordination. I've been coughing a lot and my limbs feel weak.\"\n",
        "# Indices of closest embeddings for v3 model: [[1 6 7]]\n",
        "# Distances for v3 model: [[765.25256 848.5805  867.85834]]\n",
        "# Indices of closest embeddings for v4 model: [[8 7 3]]\n",
        "# Distances for v4 model: [[829.60986 832.6284  833.5238 ]]\n",
        "# Indices of closest embeddings for v5 model: [[3 1 4]]\n",
        "# Distances for v5 model: [[537.1964  539.3674  540.19867]]\n",
        "# Indices of closest embeddings for fc_v3v4 model: [[0 3 7]]\n",
        "# Distances for fc_v3v4 model: [[1051.2994 1052.177  1052.7937]]\n",
        "# Indices of closest embeddings for fc_v4v5 model: [[4 6 2]]\n",
        "# Distances for fc_v4v5 model: [[655.0598  680.81445 682.2945 ]]\n",
        "# Indices of closest embeddings for fc_v3v5 model: [[4 6 1]]\n",
        "# Distances for fc_v3v5 model: [[635.7446 677.0921 719.471 ]]\n",
        "# Indices of closest embeddings for fcm_v5 model: [[1 2 0]]\n",
        "# Distances for fcm_v5 model: [[227.31435 227.31435 227.31435]]\n",
        "# Indices of closest embeddings for fcm_v4v5 model: [[1 2 0]]\n",
        "# Distances for fcm_v4v5 model: [[234.64517 234.64517 234.64517]]\n",
        "\n",
        "embeddings_v3 = generate_embedding_cls(text, model_v3data)\n",
        "embeddings_v4 = generate_embedding_cls(text, model_v4data)\n",
        "embeddings_v5 = generate_embedding_cls(text, model_v5data)\n",
        "\n",
        "embeddings_freeze_classifer_v3v4 = generate_embedding_cls(text, model_freeze_classifer_v3v4)\n",
        "embeddings_freeze_classifer_v4v5 = generate_embedding_cls(text, model_freeze_classifer_v4v5)\n",
        "embeddings_freeze_classifer_v3v5 = generate_embedding_cls(text, model_freeze_classifer_v3v5)\n",
        "\n",
        "embeddings_v5_max = generate_embedding_max(text, model_v5data, bert_name='tf_bert_model_2')\n",
        "embeddings_freeze_classifer_v4v5_max = generate_embedding_max(text, model_freeze_classifer_v4v5, bert_name='tf_bert_model_5')\n",
        "\n",
        "# Search the index\n",
        "k = 3\n",
        "distances_v3, indices_v3 = index_cls_v3.search(embeddings_v3, k)\n",
        "distances_v4, indices_v4 = index_cls_v4.search(embeddings_v4, k)\n",
        "distances_v5, indices_v5 = index_cls_v5.search(embeddings_v5, k)\n",
        "\n",
        "distances_fc_v3v4, indices_fc_v3v4 = index_cls_freeze_classifier_v3v4.search(embeddings_freeze_classifer_v3v4, k)\n",
        "distances_fc_v4v5, indices_fc_v4v5 = index_cls_freeze_classifier_v4v5.search(embeddings_freeze_classifer_v4v5, k)\n",
        "distances_fc_v3v5, indices_fc_v3v5 = index_cls_freeze_classifier_v3v5.search(embeddings_freeze_classifer_v3v5, k)\n",
        "\n",
        "distances_fcm_v5, indices_fcm_v5 = index_v5_max.search(embeddings_v5_max, k)\n",
        "distances_fcm_v4v5, indices_fcm_v4v5 = index_freeze_classifer_v4v5_max.search(embeddings_freeze_classifer_v4v5_max, k)\n",
        "\n",
        "print(\"Indices of closest embeddings for v3 model:\", indices_v3)\n",
        "print(\"Distances for v3 model:\", distances_v3)\n",
        "\n",
        "print(\"Indices of closest embeddings for v4 model:\", indices_v4)\n",
        "print(\"Distances for v4 model:\", distances_v4)\n",
        "\n",
        "print(\"Indices of closest embeddings for v5 model:\", indices_v5)\n",
        "print(\"Distances for v5 model:\", distances_v5)\n",
        "\n",
        "print(\"Indices of closest embeddings for fc_v3v4 model:\", indices_fc_v3v4)\n",
        "print(\"Distances for fc_v3v4 model:\", distances_fc_v3v4)\n",
        "\n",
        "print(\"Indices of closest embeddings for fc_v4v5 model:\", indices_fc_v4v5)\n",
        "print(\"Distances for fc_v4v5 model:\", distances_fc_v4v5)\n",
        "\n",
        "print(\"Indices of closest embeddings for fc_v3v5 model:\", indices_fc_v3v5)\n",
        "print(\"Distances for fc_v3v5 model:\", distances_fc_v3v5)\n",
        "\n",
        "print(\"Indices of closest embeddings for fcm_v5 model:\", indices_fcm_v5)\n",
        "print(\"Distances for fcm_v5 model:\", distances_fcm_v5)\n",
        "\n",
        "print(\"Indices of closest embeddings for fcm_v4v5 model:\", indices_fcm_v4v5)\n",
        "print(\"Distances for fcm_v4v5 model:\", distances_fcm_v4v5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IC3w_MQ4CmZ",
        "outputId": "383d8943-3760-41b6-c226-91ba480ec6f1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of closest embeddings for v3 model: [[1 6 7]]\n",
            "Distances for v3 model: [[765.25256 848.5805  867.85834]]\n",
            "Indices of closest embeddings for v4 model: [[8 7 3]]\n",
            "Distances for v4 model: [[829.60986 832.6284  833.5238 ]]\n",
            "Indices of closest embeddings for v5 model: [[3 1 4]]\n",
            "Distances for v5 model: [[537.1964  539.3674  540.19867]]\n",
            "Indices of closest embeddings for fc_v3v4 model: [[0 3 7]]\n",
            "Distances for fc_v3v4 model: [[1051.2994 1052.177  1052.7937]]\n",
            "Indices of closest embeddings for fc_v4v5 model: [[4 6 2]]\n",
            "Distances for fc_v4v5 model: [[655.0598  680.81445 682.2945 ]]\n",
            "Indices of closest embeddings for fc_v3v5 model: [[4 6 1]]\n",
            "Distances for fc_v3v5 model: [[635.7446 677.0921 719.471 ]]\n",
            "Indices of closest embeddings for fcm_v5 model: [[1 2 0]]\n",
            "Distances for fcm_v5 model: [[227.31435 227.31435 227.31435]]\n",
            "Indices of closest embeddings for fcm_v4v5 model: [[1 2 0]]\n",
            "Distances for fcm_v4v5 model: [[234.64517 234.64517 234.64517]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the prompt\n",
        "# a clear blacklist, be specific\n",
        "# setence level seems off, but if better than paragraph.. v\n",
        "# yes/no OK v\n",
        "# accurate? doubtful -> try split the prompt and clear blacklist\n",
        "# It seems v5 is the best so far."
      ],
      "metadata": {
        "id": "uLMybR4zDn9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation of two_tower_bert_v5_max (trained by token after max pooling )\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "custom_objects = {'TFBertModel': TFBertModel}\n",
        "two_tower_bert_v5_max = load_model('./drive/MyDrive/Two_tower_level4_PII/two_tower_bert_v5_max.h5', custom_objects=custom_objects)\n",
        "two_tower_bert_v5_max.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzlsMTQKbq4M",
        "outputId": "12be7697-29c6-4d57-ae7e-3c2e8f6019f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]',         \n",
            "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
            "                                n_state=(None, 128,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 768)          0           ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 100)          76900       ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            101         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,387,273\n",
            "Trainable params: 108,387,273\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"As Taylor Morgan, I am preparing to discuss my health concerns and lifestyle changes due to my recent relocation for a position at Apple's Cupertino campus.\n",
        "\"\"\"\n",
        "embeddings_v5_max = generate_embedding_max(text, two_tower_bert_v5_max, bert_name='tf_bert_model')\n",
        "embeddings_v5_max.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-WN6lIolxyz",
        "outputId": "2f1c6b40-54ab-4f26-b1a1-b75faffce1b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create vector databases\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "dimension = 768\n",
        "index_embeddings_v5_max = faiss.IndexFlatL2(dimension)\n",
        "level_four_job = [\"Competitive salary for iPhone project management roles\",\n",
        "                  \"Relocation benefits for Apple Cupertino campus positions\",\n",
        "                  \"Exclusive health and wellness benefits for iPhone development team members\",\n",
        "                  \"Stock options and bonuses for iPhone project milestones\",\n",
        "                  \"Collaborative workspaces at Apple's Silicon Valley locations\",\n",
        "                  \"Professional development programs for iOS project leads\",\n",
        "                  \"Confidentiality agreements for upcoming iPhone projects\",\n",
        "                  \"Global travel opportunities for iPhone supplier audits\",\n",
        "                  \"Flexible working hours for Apple's product development teams\",\n",
        "                  \"Team-building retreats for iPhone project managers\"]\n",
        "\n",
        "for input in level_four_job:\n",
        "  embeddings = generate_embedding_max(text, two_tower_bert_v5_max, bert_name='tf_bert_model')\n",
        "  index_embeddings_v5_max.add(embedding_vectordatabase(embeddings))\n",
        "print(index_embeddings_v5_max.ntotal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B7hIVGecCX4",
        "outputId": "55038c5e-9aad-4a11-cbee-b449f17f5a2c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f40000c7f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3fff971990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# based on \"Relocation benefits for Apple Cupertino campus positions\", ask GPT to generate a prompt (#1)\n",
        "text = \"\"\"As Taylor Morgan, I am preparing to discuss my health concerns and lifestyle changes due to my recent relocation for a position at Apple's Cupertino campus.\n",
        "\"\"\"\n",
        "# Indices of closest embeddings for v5 model: [[1 6 4]]\n",
        "# Distances for v5 model: [[149.1654  152.35236 153.35999]]\n",
        "# Indices of closest embeddings for v5 max model: [[1 2 0]]\n",
        "# Distances for v5 max model: [[0. 0. 0.]]\n",
        "\n",
        "#based on \"Global travel opportunities for iPhone supplier audits\" (#7)\n",
        "text = \"\"\"\n",
        "As Alex Rivera, I am reporting on the health implications and challenges faced due to my role involving global travel for iPhone supplier audits.\n",
        "\"\"\"\n",
        "# Indices of closest embeddings for v5 model: [[6 7 2]]\n",
        "# Distances for v5 model: [[45.748867 49.99069  51.427288]]\n",
        "# Indices of closest embeddings for v5 max model: [[1 2 0]]\n",
        "# Distances for v5 max model: [[121.72088 121.72088 121.72088]]\n",
        "\n",
        "\n",
        "# 8. longer? \"Flexible working hours for Apple's product development teams\"\n",
        "text = \"\"\"\n",
        "As Jordan Kim, I'm addressing the impact of flexible working hours on my health as part of Apple's product development team. Since the implementation of flexible working hours, I've noticed significant changes in my daily routine, some beneficial and others challenging. The ability to adjust my work hours has afforded me a greater work-life balance, allowing for more time spent with family and engaging in personal hobbies. However, without the structure of fixed working hours, I've found it difficult to establish a consistent sleep schedule, leading to occasional insomnia and varying energy levels throughout the day.\n",
        "\"\"\"\n",
        "# Indices of closest embeddings for v5 model: [[2 6 9]]\n",
        "# Distances for v5 model: [[ 98.07463  99.06271 100.05426]]\n",
        "# Indices of closest embeddings for v5 max model: [[1 2 0]]\n",
        "# Distances for v5 max model: [[165.76381 165.76381 165.76381]]\n",
        "\n",
        "\n",
        "# # 8. sentence level\n",
        "# text = \"\"\"\n",
        "# As Jordan Kim, I'm addressing the impact of flexible working hours on my health as part of Apple's product development team.\n",
        "# \"\"\"\n",
        "# # Indices of closest embeddings for v5 model: [[8 6 4]]\n",
        "# # Distances for v5 model: [[27.352757 27.495752 29.006763]]\n",
        "\n",
        "\n",
        "\n",
        "# # diagnosis, no job related information\n",
        "# text = \"I've been having a lot of pain in my neck and back. I've also been having trouble with my balance and coordination. I've been coughing a lot and my limbs feel weak.\"\n",
        "# # Indices of closest embeddings for v5 model: [[3 1 4]]\n",
        "# # Distances for v5 model: [[537.1964  539.3674  540.19867]]\n",
        "\n",
        "\n",
        "k=3\n",
        "embeddings_v5_max = generate_embedding_max(text, two_tower_bert_v5_max, bert_name='tf_bert_model')\n",
        "distances_v5_max, indices_v5_max = index_embeddings_v5_max.search(embeddings_v5_max, k)\n",
        "\n",
        "print(\"Indices of closest embeddings for v5 max model:\", indices_v5_max)\n",
        "print(\"Distances for v5 max model:\", distances_v5_max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX8yj32scpJk",
        "outputId": "313df9fd-c99b-4e1a-9b7e-1f46d906a226"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of closest embeddings for v5 max model: [[1 2 0]]\n",
            "Distances for v5 max model: [[165.76381 165.76381 165.76381]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. v5 vs. v5 trained with max_pooling.\n",
        "3. chunk prompt and do the evaluation."
      ],
      "metadata": {
        "id": "88JmLjA_aFZy"
      }
    }
  ]
}